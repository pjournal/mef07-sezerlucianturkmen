[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SEZER TURKMEN Progress Journal",
    "section": "",
    "text": "Introduction\n\nThis progress journal covers SEZER TURKMEN / YELLOW SUBMARINE’s work during their term at BDA 503 Fall 2023.\nEach section is an assignment or an individual work."
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "1  Assignment 1",
    "section": "",
    "text": "2 | ABOUT ME\nGreetings!\nI’m Sezer Turkmen, a software developer whose journey spans the realms of architecture and coding. In a nutshell:\n\n2.0.1 From Architect to Code Creator: My Transition\nI initially ventured into the world of architecture, my first passion. My studies took me to Italy, where I delved into multi-scale architecture and sustainable design, honing my eye for detail and love for harmonious structures.\nAfter working as an architect for a considerable period, I felt the magnetic pull towards coding. The allure of shaping digital landscapes was irresistible, prompting a career shift.\n\n\n2.0.2 Mastering Full Stack Development\nAs a software developer, I immersed myself in coding, mastering Java and venturing into full-stack development. I used technologies like Spring Boot and React to craft dynamic, user-friendly applications. Kubernetes and Docker added efficiency and scalability to my toolkit, bridging the worlds of traditional and digital architecture.\nMy journey is guided by the belief in perpetual learning. I attended a coding bootcamp to refine my skills and gain practical insights, cementing my passion for coding. As a software developer, I enjoy creating elegant, user-centric applications.\nCurrently, I’m pursuing a master’s in Information Technologies at MEF University, ensuring my knowledge stays cutting-edge.\n\n\n2.0.3 Life Beyond Tech\nOutside of coding and architecture, I find joy in cooking, a creative outlet where flavors and textures are my canvas. Staying active is another passion. Whether it’s hitting the gym or enjoying indoor cycling with a spirited playlist, I cherish the rhythm and precision of physical activity.\n\n\n2.0.4 The Future Awaits\nI’m Sezer Turkmen, a full-stack developer, architect, and a lover of life. My mission is to blend creativity and technology, one line of code at a time. Thank you for getting to know me!\n  \n\n\n\n\n3 | DISCOVER THE POSIT\n\n3.0.1 YouTube Channel | The open-source data science company for the individual, team and enterprise.\n\n\n\n\nTeaching R online with RStudio Cloud\nI chose to watch the video titled “Mine Çetinkaya-Rundel | Teaching R online with RStudio Cloud” for two main reasons. Firstly, I was interested in learning about effective online teaching methods for the R programming language, commonly used in data science. The video delves into the benefits of using RStudio Cloud for teaching, emphasizing its user-friendly approach. Additionally, I was drawn to the fact that the presenter, Mine Çetinkaya-Rundel, shares a Turkish background with me, which added a unique cultural perspective to the subject matter. The presentation covers tips and best practices for using RStudio Cloud effectively in the classroom, as exporting and grading student work and sharing data files.\n\n\n\n\n4 | PROPOSE DATASET\n\n4.0.1 Most Streamed Spotify Songs 2023\nThe ‘Most Streamed Spotify Songs 2023’ dataset is a fantastic choice for class demos. It offers insights into the music industry by showcasing popular songs and their attributes. Students can explore the science of hit songs, understand their impact through social media analysis, and learn about cross-platform music data. It’s engaging and up-to-date, making it an excellent teaching resource.\n\n# Use Google Drive to connect Dataset with library of 'googleDrive'\nid &lt;- \"1nM0Cr-gVFF9UjvxSZXHNfFnrDWIUoTHi\"\ntotal_list &lt;- read.csv(sprintf(\"https://docs.google.com/uc?id=%s&export=download\", id))\n\n# Filter out rows with non-numeric values in the 'streams' column\nfiltered_spotify_data &lt;- total_list %&gt;%\n   filter(!grepl(\"[a-zA-Z]\", streams))\n\n# Sort the filtered dataset by the 'streams' column in descending order\nsorted_filtered_spotify_data &lt;- filtered_spotify_data %&gt;%\n  arrange(desc(streams))\n\n# Create HTML view of Dataset\nDT::datatable(head(sorted_filtered_spotify_data), editable = list(\n  target = 'row', disable = list(columns = c(1, 3, 4))\n))\n\n\n\n\n\n\n\nThe Most Streamed Spotify Songs 2023 dataset contains a comprehensive list of the most famous songs of 2023 as listed on Spotify. The dataset offers a wealth of features beyond what is typically available in similar datasets. It provides insights into each song’s attributes, popularity, and presence on various music platforms. The dataset includes information such as track name, artist(s) name, release date, Spotify playlists and charts, streaming statistics, Apple Music presence, Deezer presence, Shazam charts, and various audio features.\nGO KAGGLE FOR THIS DATASET\n\n\n\n\n5 | LEARN THREE R POST\n\n5.0.1 Creating Stunning Visuals with ggplot2 and ggExtra\nVisualizing the distribution of data is essential for understanding it better. In R, you can use ggplot2 and ggExtra to create informative charts.\nggplot2 is a popular tool for making all sorts of graphs. It’s user-friendly and versatile, letting you customize your plots easily.\nggExtra is like an upgrade for ggplot2, designed to make scatterplots and other graphs even more helpful. It adds histograms or density plots to the sides of your main chart, showing you how individual data points are spread out. This extra information helps you grasp your data’s patterns.\nTo use ggplot2 and ggExtra, first, make your main chart with ggplot2, and then use ggExtra’s function, ggMarginal(), to include those extra histograms or density plots. This adds depth to your visualizations, helping you understand data distributions better.\nIn a nutshell, ggplot2 and ggExtra are handy tools in R for exploring and presenting data, making your visualizations more informative and user-friendly.\n\n# library\nlibrary(ggplot2)\nlibrary(ggExtra)\n \n# classic plot :\np &lt;- ggplot(mtcars, aes(x=wt, y=mpg, color=cyl, size=cyl)) +\n      geom_point() +\n      theme(legend.position=\"none\")\n \n# Set relative size of marginal plots (main plot 10x bigger than marginals)\nggMarginal(p, type=\"histogram\", size=10)\n \n# Custom marginal plots:\nggMarginal(p, type=\"histogram\", fill = \"slateblue\", xparams = list(  bins=10))\n \n# Show only marginal plot for x axis\nggMarginal(p, margins = 'x', color=\"purple\", size=4)\n\n\n\n# Very basic chart\nggplot( mtcars , aes(x=mpg, y=wt)) + \n  geom_point()\n\n\n\n\nSEE MORE\n\n\n\n5.0.2 Text Analysis || Text Mining in R\nText analysis, or text mining, is a vital tool for extracting insights from unstructured text data. It’s essential because it helps us understand, categorize, and derive meaningful information from sources like social media, customer feedback, research papers, and more. For instance, it enables sentiment analysis to gauge public opinions, topic modeling for content organization, and efficient information retrieval from large datasets. In R, a popular choice for text analysis, you can use libraries like ‘tm’ and ‘tidytext’ to perform tasks like text preprocessing and visualizing word frequency, as demonstrated in the provided code. This skill empowers you to make data-driven decisions and save time by automating text processing tasks. Happy text mining!\n\nlibrary(stringr)\n#All functions in stringr start with str_ and take a vector of strings as the first argument:\n\nx &lt;- c(\"why\", \"video\", \"cross\", \"extra\", \"deal\", \"authority\")\nstr_length(x) \n\n[1] 3 5 5 5 4 9\n\nstr_c(x, collapse = \", \")\n\n[1] \"why, video, cross, extra, deal, authority\"\n\nstr_sub(x, 1, 2)\n\n[1] \"wh\" \"vi\" \"cr\" \"ex\" \"de\" \"au\"\n\n#Most string functions work with regular expressions, a concise language for describing patterns of text. For example, the regular expression \"[aeiou]\" matches any single character that is a vowel:\n\nstr_subset(x, \"[aeiou]\")\n\n[1] \"video\"     \"cross\"     \"extra\"     \"deal\"      \"authority\"\n\nstr_count(x, \"[aeiou]\")\n\n[1] 0 3 1 2 2 4\n\n#There are seven main verbs that work with patterns:\n\n# str_detect(x, pattern) tells you if there’s any match to the pattern:\n\nstr_detect(x, \"[aeiou]\")\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n#str_count(x, pattern) counts the number of patterns:\n\nstr_count(x, \"[aeiou]\")\n\n[1] 0 3 1 2 2 4\n\n#str_subset(x, pattern) extracts the matching components:\n\nstr_subset(x, \"[aeiou]\")\n\n[1] \"video\"     \"cross\"     \"extra\"     \"deal\"      \"authority\"\n\n#str_locate(x, pattern) gives the position of the match:\n\n\nstr_replace(x, \"[aeiou]\", \"?\")\n\n[1] \"why\"       \"v?deo\"     \"cr?ss\"     \"?xtra\"     \"d?al\"      \"?uthority\"\n\n#str_split(x, pattern) splits up a string into multiple pieces:\n\n#fixed(): match exact bytes\n#coll(): match human letters\n#boundary(): match boundaries\n\nSEE MORE\n\n\n\n5.0.3 Random Forest in R\nThe randomForest package in R is a highly popular and effective tool for implementing ensemble learning techniques and constructing models based on decision trees. By harnessing the power of random forests, this package excels in producing reliable and precise predictions, making it well-suited for tasks involving high-dimensional datasets. Its versatility extends to both classification and regression challenges, where it can significantly enhance the quality of predictions by combining insights from multiple decision trees.\n\n#library(randomForest)\n#library(ggplot2)\n\nset.seed(4543)\ndata(mtcars)\nrf.fit &lt;- randomForest(mpg ~ ., data=mtcars, ntree=1000,\n                       keep.forest=FALSE, importance=TRUE)\n\nIn R, random forest regression permits parameter experimentation, such as adjusting ntree and mtry to assess their effects on residuals and variance. Importance metrics encompass mean square error (MSE) and node purity. For reliable variable importance evaluation, prioritize MSE. In cases where predictors are exclusively numerical, prioritize MSE when metrics diverge. Visualize importance results using varImpPlot(), and for enhanced insights, create a combined plot that accentuates MSE outcomes, providing a comprehensive view of variable importance in random forest regression models.\n\n# Get variable importance from the model fit\nImpData &lt;- as.data.frame(importance(rf.fit))\nImpData$Var.Names &lt;- row.names(ImpData)\n\nggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +\n  geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color=\"skyblue\") +\n  geom_point(aes(size = IncNodePurity), color=\"blue\", alpha=0.6) +\n  theme_light() +\n  coord_flip() +\n  theme(\n    legend.position=\"bottom\",\n    panel.grid.major.y = element_blank(),\n    panel.border = element_blank(),\n    axis.ticks.y = element_blank()\n  )\n\n\n\n\nSEE MORE"
  },
  {
    "objectID": "inClass1.html",
    "href": "inClass1.html",
    "title": "2  In Class 1",
    "section": "",
    "text": "2.0.1 Most Streamed Spotify Songs 2023\nThe ‘Most Streamed Spotify Songs 2023’ dataset is a fantastic choice for class demos. It offers insights into the music industry by showcasing popular songs and their attributes. Students can explore the science of hit songs, understand their impact through social media analysis, and learn about cross-platform music data. It’s engaging and up-to-date, making it an excellent teaching resource.\n\n# Use Google Drive to connect Dataset with library of 'googleDrive'\nid &lt;- \"1nM0Cr-gVFF9UjvxSZXHNfFnrDWIUoTHi\"\ntotal_list &lt;- read.csv(sprintf(\"https://docs.google.com/uc?id=%s&export=download\", id))\n\n# Filter out rows with non-numeric values in the 'streams' column\nfiltered_spotify_data &lt;- total_list %&gt;%\n   filter(!grepl(\"[a-zA-Z]\", streams))\n\n# Sort the filtered dataset by the 'streams' column in descending order\nsorted_filtered_spotify_data &lt;- filtered_spotify_data %&gt;%\n  arrange(desc(streams))\n\n# Create HTML view of Dataset\nDT::datatable(head(sorted_filtered_spotify_data), editable = list(\n  target = 'row', disable = list(columns = c(1, 3, 4))\n))\n\n\n\n\n\n\n\n\n\n2.0.2 Exercises\n\nclass(filtered_spotify_data$streams)\n\n[1] \"character\"\n\n# Convert character to numeric , original r\nfiltered_spotify_data$streams &lt;- as.numeric(filtered_spotify_data$streams)\n\n# 1. The mean of all streams in the dataset\nmean_streams &lt;- filtered_spotify_data %&gt;%\n  summarise(mean_streams = mean(streams, na.rm = TRUE))\n\nprint(mean_streams)\n\n  mean_streams\n1    514137425\n\n# 2. The mean of streams for each month\nmonth_names &lt;- month.name\n\nmean_streams_by_month &lt;- filtered_spotify_data %&gt;%\n  group_by(released_month) %&gt;%\n  summarise(mean_streams = mean(streams, na.rm = TRUE)) %&gt;%\n  mutate(released_month = month_names[as.numeric(released_month)])\n\nprint(mean_streams_by_month)\n\n# A tibble: 12 × 2\n   released_month mean_streams\n   &lt;chr&gt;                 &lt;dbl&gt;\n 1 January          727506137.\n 2 February         353153502.\n 3 March            477052609.\n 4 April            404145980.\n 5 May              415669054.\n 6 June             410044671.\n 7 July             482176478.\n 8 August           631265701.\n 9 September        734644353.\n10 October          588902402.\n11 November         552592271.\n12 December         369573392.\n\n# 3. Transmute mutate example\nspotify_data_millions &lt;- filtered_spotify_data %&gt;%\n  mutate(streams_in_millions = streams / 1000000) %&gt;%\n  transmute(track_name, artist.s._name, released_year, streams_in_millions) %&gt;%\n  arrange(desc(streams_in_millions))\n\nprint(head(spotify_data_millions))\n\n                                     track_name        artist.s._name\n1                               Blinding Lights            The Weeknd\n2                                  Shape of You            Ed Sheeran\n3                             Someone You Loved         Lewis Capaldi\n4                                  Dance Monkey           Tones and I\n5 Sunflower - Spider-Man: Into the Spider-Verse Post Malone, Swae Lee\n6                                     One Dance   Drake, WizKid, Kyla\n  released_year streams_in_millions\n1          2019            3703.895\n2          2017            3562.544\n3          2018            2887.242\n4          2019            2864.792\n5          2018            2808.097\n6          2016            2713.922"
  },
  {
    "objectID": "inClass2.html",
    "href": "inClass2.html",
    "title": "3  In Class 2",
    "section": "",
    "text": "3.0.1 Most Streamed Spotify Songs 2023\nThe ‘Most Streamed Spotify Songs 2023’ dataset is a fantastic choice for class demos. It offers insights into the music industry by showcasing popular songs and their attributes. Students can explore the science of hit songs, understand their impact through social media analysis, and learn about cross-platform music data. It’s engaging and up-to-date, making it an excellent teaching resource.\n\n# Use Google Drive to connect Dataset with library of 'googleDrive'\nid &lt;- \"1nM0Cr-gVFF9UjvxSZXHNfFnrDWIUoTHi\"\ntotal_list &lt;- read.csv(sprintf(\"https://docs.google.com/uc?id=%s&export=download\", id))\n\n# Filter out rows with non-numeric values in the 'streams' column\nfiltered_spotify_data &lt;- total_list %&gt;%\n   filter(!grepl(\"[a-zA-Z]\", streams))\n\n# Sort the filtered dataset by the 'streams' column in descending order\nsorted_filtered_spotify_data &lt;- filtered_spotify_data %&gt;%\n  arrange(desc(streams))\n\n# Create HTML view of Dataset\nDT::datatable(head(sorted_filtered_spotify_data), editable = list(\n  target = 'row', disable = list(columns = c(1, 3, 4))\n))\n\n\n\n\n\n\n\n\n\n3.0.2 Exercises for GGPLOT2\nPractising the GGPLOT2, visualize Spotify data with three exercises. First, a bar chart illustrates the distribution of musical features. Second, a line plot depicts stream trends over time. Lastly, a dot plot showcases the top 10 artists with the highest streams, offering insights into their popularity.\n\nclass(filtered_spotify_data$streams)\n\n[1] \"character\"\n\n# Convert character to numeric , original r\nfiltered_spotify_data$streams &lt;- as.numeric(filtered_spotify_data$streams)\n\n# 1. Distribution of Musical Features\n\nordered_filtered_data &lt;- filtered_spotify_data[order(-filtered_spotify_data$streams), ]\n\ntop100_streams_data &lt;- head(ordered_filtered_data, 100)\n\ngathered_top100_data &lt;- gather(top100_streams_data, key = \"feature\", value = \"percentage\",\n                                danceability_., valence_., energy_., acousticness_., instrumentalness_.)\n\nggplot(gathered_top100_data, aes(x = feature, y = percentage, fill = feature)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", color = \"black\") +\n  labs(title = \"Distribution of Musical Features (Top 100 Streams)\",\n       x = \"Musical Features\",\n       y = \"Percentage\",\n       fill = \"Feature\") +\n  theme_minimal()\n\n\n\n# 2. Line Plot for Streams over Time\nggplot(filtered_spotify_data, aes(x = released_year, y = streams, group = 1)) +\n  geom_line(color = \"green\") +\n  labs(title = \"Line Plot for Streams over Time\",\n       x = \"Released Year\",\n       y = \"Streams\")\n\n\n\n# 3. Dot Plot for Top 10 Artists with Highest Streams\n\ntop_artists &lt;- filtered_spotify_data %&gt;%\n  group_by(artist.s._name) %&gt;%\n  summarise(total_streams = sum(streams)) %&gt;%\n  top_n(10, total_streams)\n\nggplot(top_artists, aes(x = reorder(artist.s._name, total_streams), y = total_streams, fill = artist.s._name)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", dotsize = 2) +\n  labs(title = \"Dot Plot for Top 10 Artists with Highest Streams\",\n       x = \"Artist\",\n       y = \"Total Streams\",\n       fill = \"Artist\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`."
  },
  {
    "objectID": "assignment_shiny.html#shiny-app-spotify-data-exploration",
    "href": "assignment_shiny.html#shiny-app-spotify-data-exploration",
    "title": "4  Assignment: Shiny",
    "section": "4.1 Shiny App: Spotify Data Exploration",
    "text": "4.1 Shiny App: Spotify Data Exploration\nThis Shiny app explores Spotify data, focusing on trends in various music features over the years. The data source is a dataset containing information on streams, release years, and different music attributes.\nYou can run my shiny app using the following command.\n\nlibrary(shiny)\nshiny::runGitHub(\"pjournal/mef07-sezerlucianturkmen\", subdir = \"/app/app.R\")"
  },
  {
    "objectID": "assignment_shiny.html#shiny-spotify-link",
    "href": "assignment_shiny.html#shiny-spotify-link",
    "title": "4  Assignment: Shiny",
    "section": "4.2 Shiny Spotify Link",
    "text": "4.2 Shiny Spotify Link\nYou can run my Shiny app by clicking on the image below:\n\n\n\n\n\n\nAlso, you can try the app on Shinyapps."
  },
  {
    "objectID": "ORAssignment.html",
    "href": "ORAssignment.html",
    "title": "5  OR Assignment",
    "section": "",
    "text": "6 Optimizing Gate and Stand Assignments at Copenhagen Airport"
  },
  {
    "objectID": "ORAssignment.html#business-situation",
    "href": "ORAssignment.html#business-situation",
    "title": "5  OR Assignment",
    "section": "6.1 Business Situation",
    "text": "6.1 Business Situation\nCopenhagen Airport (CPH) faced a challenge similar to finding parking in a busy lot, but with aircraft stands. The airport needed to maximize the use of existing stands and plan for future expansion cost-effectively. Each new stand cost $10M USD (30M-50M DDK), prompting the need for a precise optimization strategy."
  },
  {
    "objectID": "ORAssignment.html#building-the-model",
    "href": "ORAssignment.html#building-the-model",
    "title": "5  OR Assignment",
    "section": "6.2 Building the Model",
    "text": "6.2 Building the Model\nThe Operational Research (OR) team at CPH developed a detailed optimization model, moving away from traditional top-down analyses. They incorporated operational requirements and restrictions into the model, considering hard constraints (specific aircraft types for certain stands) and softer preferences (airlines’ proximity preferences). The mathematical model was constructed in two months using the Gurobi C++ API."
  },
  {
    "objectID": "ORAssignment.html#results",
    "href": "ORAssignment.html#results",
    "title": "5  OR Assignment",
    "section": "6.3 Results",
    "text": "6.3 Results\nGurobi efficiently found solutions, offering valuable insights and identifying areas for refinement. The model, with additional operational details, enabled quick what-if analyses for decision trade-offs. The optimized plan recommended by the model led to investments totaling over $70M USD ($400M DDK) in new stands and gates."
  },
  {
    "objectID": "ORAssignment.html#benefits",
    "href": "ORAssignment.html#benefits",
    "title": "5  OR Assignment",
    "section": "6.4 Benefits",
    "text": "6.4 Benefits\n\nCost Savings: Gurobi’s model led to $79M USD in savings by optimizing stand assignments and guiding strategic investments.\nEfficient Utilization: Gurobi maximized existing stand usage, ensuring precise allocation based on aircraft types and airlines’ preferences for improved efficiency.\nQuick Decision-Making: Gurobi’s fast solutions facilitated swift decision-making, enabling the team to adapt to changing scenarios effectively.\nFlexibility and Adaptability: The model easily adapted to operational changes, accommodating soft preferences and ensuring efficient decision-making.\nStrategic Planning: The optimized plan not only addressed current challenges but also served as a guide for future expansions, ensuring long-term sustainability.\nUser-Friendly Interface: Leveraging Excel made the process user-friendly, enhancing collaboration and integration into existing workflows."
  },
  {
    "objectID": "ORAssignment.html#reference",
    "href": "ORAssignment.html#reference",
    "title": "5  OR Assignment",
    "section": "6.5 Reference",
    "text": "6.5 Reference\nCopenhagen Airport Case Study"
  }
]